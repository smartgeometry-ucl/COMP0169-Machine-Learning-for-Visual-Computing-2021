{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PRiDl3S1eYW"
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIFxgVmXgCu1"
   },
   "outputs": [],
   "source": [
    "# Lets import some libraries \n",
    "import torch # PyTorch \n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets # Datasets module \n",
    "from torchvision import transforms # Image Transforms \n",
    "from torchvision import models as pretrained_models # Pretrained models\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DhMTQ7Ff0BWF"
   },
   "source": [
    "##### Code to load custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hJEWCBqK0FC4"
   },
   "outputs": [],
   "source": [
    "def load_custom_image(path):\n",
    "    \"\"\"\n",
    "    Load image from path\n",
    "\n",
    "    Return a Pytorch image tensor\n",
    "    \"\"\"\n",
    "\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    # BGR to RGB\n",
    "    img = img[:, :, [2,1,0]]\n",
    "    \n",
    "    # Create a pytorch tensor from numpy\n",
    "    img_pt = torch.from_numpy(img).float()\n",
    "    \n",
    "    # Add an extra 'batch' dimesion by unsqueeze\n",
    "    # Convert the [B,H,W,3] image to [B,3,H,W]\n",
    "    # These are necessary to feed image to pytorch networks\n",
    "    img_pt = img_pt.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "    \n",
    "    return img_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSW29elLgaYv"
   },
   "source": [
    "# Example 1\n",
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4caQXwd3gclk"
   },
   "outputs": [],
   "source": [
    "def predict(test_loader, model, classes,scale=1):\n",
    "    \"\"\"\n",
    "    This function will be used to predict using the trained neural network\n",
    "    'model', and evaluate classification accuracy and show example images\n",
    "    that are classified.\n",
    "\n",
    "    Arguments:\n",
    "    test_loader : Pytorch data loader. We iterate over this to obtain samples\n",
    "    model : The neural network model object\n",
    "    classes : The names of the classes\n",
    "    \"\"\"\n",
    "\n",
    "    # Move model to GPU\n",
    "    model = model.cuda()\n",
    "\n",
    "    # No gradients, since we're evaluating and not training\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "\n",
    "        # Iterate over the dataset\n",
    "        for data, target in test_loader:\n",
    "            # Data and its corresponding labels\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # Predicted labels, using the model\n",
    "            predictions = model(data)\n",
    "\n",
    "            # Evaluate accuracy by comparing prediction to target\n",
    "            predictions_index = predictions.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += predictions_index.eq(target.view_as(predictions_index)).long().cpu().sum()\n",
    "\n",
    "    print('\\nTest set accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # We have prediction indices, now print the label names using those \n",
    "    for p in predictions_index:\n",
    "        print(classes[p])\n",
    "\n",
    "    # Show some of the images.\n",
    "    plt.figure()\n",
    "    for i in range(data.size(0)):\n",
    "        if data[i].size(0) == 3:\n",
    "            pred = torch.unsqueeze(data[i].cpu(),0)\n",
    "            resized = F.interpolate(pred,scale_factor=scale,mode='bicubic')\n",
    "            plt.imshow(resized[0].permute(1,2,0))\n",
    "        else:\n",
    "            plt.imshow(data[i].permute(1,2,0).cpu().squeeze(), cmap='gray')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGXSptGvTghj"
   },
   "source": [
    "#### MNIST example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471,
     "referenced_widgets": [
      "6434d040e1ec4290bcc17cc83f7f186f",
      "593ce3e905c244e280eef58f071c6312",
      "6188895479914d6c879ad151acc23b56",
      "eae088d584f44016ac781564de939e87",
      "974818abc603428c84f745fdf6c8e3fa",
      "07fdd2088bda401382643496e800ff7d",
      "41e67cf900f148448f7f2d31d8ddafed",
      "d81f37d4b1494eb4ba9442a0c83764e1",
      "45a6ada590e045bb8cf92bd276725716",
      "6f5a317063d64eeda925c7bf2b2e3e7f",
      "de53205fdccc41108b6da2eb9e4b30a8"
     ]
    },
    "id": "GosRfK6CP4Gy",
    "outputId": "e1e9194e-06a8-4eff-f8ef-33dabdf009a2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the MNIST dataset. Pytorch has some datasets in the library, MNIST is one \n",
    "of them\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the dataset. Apply transformation to each image\n",
    "mnist_data = datasets.MNIST('../data', train=False, \n",
    "                    download=True, \n",
    "                    # The transform is applied to each image\n",
    "                    transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean=[0.1307], std=[0.3081])\n",
    "                   ])\n",
    "                )\n",
    "\n",
    "# Initializing the torch data loader using the dataset\n",
    "mnist_test_loader = torch.utils.data.DataLoader(mnist_data,\n",
    "                                          batch_size=5,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# Class ids\n",
    "classes = list(range(0,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ta23kYRTR2M",
    "outputId": "3de8ef53-283a-472d-f1b5-19c30144475e"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Pytorch has some pretrained neural network models. We're going to use \n",
    "a pretrained Alexnet to do some classification\n",
    "\"\"\"\n",
    "\n",
    "alexnet = pretrained_models.alexnet()\n",
    "alexnet.features[0] = torch.nn.Conv2d(1,64, kernel_size=3)\n",
    "alexnet.classifier[6] = torch.nn.Linear(4096,10)\n",
    "\n",
    "# Get the trained weights, and load it into pytorch's Alexnet\n",
    "!wget \"https://www.dropbox.com/s/g3wol62g3s9wdjk/mnist_net.pth?dl=1\" -O 'mnist_net.pth'\n",
    "alexnet.load_state_dict(torch.load('mnist_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ksFzpM9hTshk",
    "outputId": "0d97587d-340d-4082-8ee5-40304e68f41f"
   },
   "outputs": [],
   "source": [
    "# Predict on some MNIST Images using Alexnet\n",
    "predict(mnist_test_loader, alexnet, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsWmLr3aTa_X"
   },
   "source": [
    "#### CIFAR10 example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "79caf1d9277a4f61be502d131f5900f5",
      "1e5a6e4a979b4a668b95fd422eb575f1",
      "dd60d5286eae470b84168ba5643fa459",
      "e1b74aa2c2b24d0a94cad31a3b3393b1",
      "67b546d1833f4d1bbd74e41839cfc437",
      "553ae8541d474af29a68334d723180af",
      "58758fb0a34c4a2a8c8a55c5df15f7f4",
      "d91e902730b64b2e83effd4ba193d418",
      "d72765fb9bb3448cb51876401603bb9f",
      "3f2435c919df47e4813cae97d5bfe9b3",
      "3ee80943b8a549de99b41534cea0e34a"
     ]
    },
    "id": "RXFMp0zogb5W",
    "outputId": "ac5dbdc9-e2fe-4dbe-9057-55808f68fc00"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we'll test with CIFAR-10 dataset\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the dataset. Apply transformation to each image\n",
    "cifar_data = datasets.CIFAR10('../data', train=False, \n",
    "                    download=True,  \n",
    "                    transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                            std=[0.229, 0.224, 0.225])\n",
    "                   ])\n",
    ")\n",
    "\n",
    "# Initialize torch data loader using initialized dataset                \n",
    "cifar_test_loader = torch.utils.data.DataLoader(cifar_data,\n",
    "                                          batch_size=5,\n",
    "                                          shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OYUnjqPJgchB",
    "outputId": "5e1c0e81-40c2-4bb5-d672-c5eeebb6080b"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Another pre-trained model available in Pytorch is VGG-16. We'll predict CIFAR-10 classes with that.\n",
    "\"\"\"\n",
    "\n",
    "vgg16 = pretrained_models.vgg16()\n",
    "vgg16.classifier[6] = torch.nn.Linear(4096,10)\n",
    "\n",
    "# Get and load pre-trained weights into pytorch's VGG-16\n",
    "!wget \"https://www.dropbox.com/s/0rye71o7gngzgwa/cifar10_net.pth?dl=1\" -O 'cifar10_net.pth'\n",
    "vgg16.load_state_dict(torch.load('cifar10_net.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zDsC_-TCj69N",
    "outputId": "5680a4c9-a2f0-4a49-9b22-fe33109799d0"
   },
   "outputs": [],
   "source": [
    "# Predict CIFAR-10 classes using VGG-16\n",
    "predict(cifar_test_loader, vgg16, classes,scale=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YeFlnbOmw56"
   },
   "source": [
    "Check [HERE](https://pytorch.org/vision/stable/models.html#classification) to see what other model you can test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38JyGges0TQY"
   },
   "source": [
    "# Example 2\n",
    "Object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R35s9eUGFJFf",
    "outputId": "220e9103-e391-42cc-d516-a799f9587ad7"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We use the COCO dataset, to test object detection.\n",
    "\"\"\"\n",
    "\n",
    "!wget http://images.cocodataset.org/zips/val2017.zip\n",
    "!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "!unzip val2017.zip\n",
    "!unzip annotations_trainval2017.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1gWPhAfGZ2Wz"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Some bookkeeping code to map class ids to class names. Ignore this cell\n",
    "\"\"\"\n",
    "\n",
    "category_data = [{\"supercategory\": \"person\",\"id\": 1,\"name\": \"person\"},{\"supercategory\": \"vehicle\",\"id\": 2,\"name\": \"bicycle\"},{\"supercategory\": \"vehicle\",\"id\": 3,\"name\": \"car\"},{\"supercategory\": \"vehicle\",\"id\": 4,\"name\": \"motorcycle\"},{\"supercategory\": \"vehicle\",\"id\": 5,\"name\": \"airplane\"},{\"supercategory\": \"vehicle\",\"id\": 6,\"name\": \"bus\"},{\"supercategory\": \"vehicle\",\"id\": 7,\"name\": \"train\"},{\"supercategory\": \"vehicle\",\"id\": 8,\"name\": \"truck\"},{\"supercategory\": \"vehicle\",\"id\": 9,\"name\": \"boat\"},{\"supercategory\": \"outdoor\",\"id\": 10,\"name\": \"traffic light\"},{\"supercategory\": \"outdoor\",\"id\": 11,\"name\": \"fire hydrant\"},{\"supercategory\": \"outdoor\",\"id\": 13,\"name\": \"stop sign\"},{\"supercategory\": \"outdoor\",\"id\": 14,\"name\": \"parking meter\"},{\"supercategory\": \"outdoor\",\"id\": 15,\"name\": \"bench\"},{\"supercategory\": \"animal\",\"id\": 16,\"name\": \"bird\"},{\"supercategory\": \"animal\",\"id\": 17,\"name\": \"cat\"},{\"supercategory\": \"animal\",\"id\": 18,\"name\": \"dog\"},{\"supercategory\": \"animal\",\"id\": 19,\"name\": \"horse\"},{\"supercategory\": \"animal\",\"id\": 20,\"name\": \"sheep\"},{\"supercategory\": \"animal\",\"id\": 21,\"name\": \"cow\"},{\"supercategory\": \"animal\",\"id\": 22,\"name\": \"elephant\"},{\"supercategory\": \"animal\",\"id\": 23,\"name\": \"bear\"},{\"supercategory\": \"animal\",\"id\": 24,\"name\": \"zebra\"},{\"supercategory\": \"animal\",\"id\": 25,\"name\": \"giraffe\"},{\"supercategory\": \"accessory\",\"id\": 27,\"name\": \"backpack\"},{\"supercategory\": \"accessory\",\"id\": 28,\"name\": \"umbrella\"},{\"supercategory\": \"accessory\",\"id\": 31,\"name\": \"handbag\"},{\"supercategory\": \"accessory\",\"id\": 32,\"name\": \"tie\"},{\"supercategory\": \"accessory\",\"id\": 33,\"name\": \"suitcase\"},{\"supercategory\": \"sports\",\"id\": 34,\"name\": \"frisbee\"},{\"supercategory\": \"sports\",\"id\": 35,\"name\": \"skis\"},{\"supercategory\": \"sports\",\"id\": 36,\"name\": \"snowboard\"},{\"supercategory\": \"sports\",\"id\": 37,\"name\": \"sports ball\"},{\"supercategory\": \"sports\",\"id\": 38,\"name\": \"kite\"},{\"supercategory\": \"sports\",\"id\": 39,\"name\": \"baseball bat\"},{\"supercategory\": \"sports\",\"id\": 40,\"name\": \"baseball glove\"},{\"supercategory\": \"sports\",\"id\": 41,\"name\": \"skateboard\"},{\"supercategory\": \"sports\",\"id\": 42,\"name\": \"surfboard\"},{\"supercategory\": \"sports\",\"id\": 43,\"name\": \"tennis racket\"},{\"supercategory\": \"kitchen\",\"id\": 44,\"name\": \"bottle\"},{\"supercategory\": \"kitchen\",\"id\": 46,\"name\": \"wine glass\"},{\"supercategory\": \"kitchen\",\"id\": 47,\"name\": \"cup\"},{\"supercategory\": \"kitchen\",\"id\": 48,\"name\": \"fork\"},{\"supercategory\": \"kitchen\",\"id\": 49,\"name\": \"knife\"},{\"supercategory\": \"kitchen\",\"id\": 50,\"name\": \"spoon\"},{\"supercategory\": \"kitchen\",\"id\": 51,\"name\": \"bowl\"},{\"supercategory\": \"food\",\"id\": 52,\"name\": \"banana\"},{\"supercategory\": \"food\",\"id\": 53,\"name\": \"apple\"},{\"supercategory\": \"food\",\"id\": 54,\"name\": \"sandwich\"},{\"supercategory\": \"food\",\"id\": 55,\"name\": \"orange\"},{\"supercategory\": \"food\",\"id\": 56,\"name\": \"broccoli\"},{\"supercategory\": \"food\",\"id\": 57,\"name\": \"carrot\"},{\"supercategory\": \"food\",\"id\": 58,\"name\": \"hot dog\"},{\"supercategory\": \"food\",\"id\": 59,\"name\": \"pizza\"},{\"supercategory\": \"food\",\"id\": 60,\"name\": \"donut\"},{\"supercategory\": \"food\",\"id\": 61,\"name\": \"cake\"},{\"supercategory\": \"furniture\",\"id\": 62,\"name\": \"chair\"},{\"supercategory\": \"furniture\",\"id\": 63,\"name\": \"couch\"},{\"supercategory\": \"furniture\",\"id\": 64,\"name\": \"potted plant\"},{\"supercategory\": \"furniture\",\"id\": 65,\"name\": \"bed\"},{\"supercategory\": \"furniture\",\"id\": 67,\"name\": \"dining table\"},{\"supercategory\": \"furniture\",\"id\": 70,\"name\": \"toilet\"},{\"supercategory\": \"electronic\",\"id\": 72,\"name\": \"tv\"},{\"supercategory\": \"electronic\",\"id\": 73,\"name\": \"laptop\"},{\"supercategory\": \"electronic\",\"id\": 74,\"name\": \"mouse\"},{\"supercategory\": \"electronic\",\"id\": 75,\"name\": \"remote\"},{\"supercategory\": \"electronic\",\"id\": 76,\"name\": \"keyboard\"},{\"supercategory\": \"electronic\",\"id\": 77,\"name\": \"cell phone\"},{\"supercategory\": \"appliance\",\"id\": 78,\"name\": \"microwave\"},{\"supercategory\": \"appliance\",\"id\": 79,\"name\": \"oven\"},{\"supercategory\": \"appliance\",\"id\": 80,\"name\": \"toaster\"},{\"supercategory\": \"appliance\",\"id\": 81,\"name\": \"sink\"},{\"supercategory\": \"appliance\",\"id\": 82,\"name\": \"refrigerator\"},{\"supercategory\": \"indoor\",\"id\": 84,\"name\": \"book\"},{\"supercategory\": \"indoor\",\"id\": 85,\"name\": \"clock\"},{\"supercategory\": \"indoor\",\"id\": 86,\"name\": \"vase\"},{\"supercategory\": \"indoor\",\"id\": 87,\"name\": \"scissors\"},{\"supercategory\": \"indoor\",\"id\": 88,\"name\": \"teddy bear\"},{\"supercategory\": \"indoor\",\"id\": 89,\"name\": \"hair drier\"},{\"supercategory\": \"indoor\",\"id\": 90,\"name\": \"toothbrush\"}]\n",
    "\n",
    "classid_to_name = {}\n",
    "\n",
    "\n",
    "for data_dict in category_data:\n",
    "  id_number = data_dict['id']\n",
    "  name = data_dict['name']\n",
    "  classid_to_name[id_number] = name\n",
    "\n",
    "max_id = max(classid_to_name.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bDD8guyHI3P",
    "outputId": "b6725414-3f04-401e-a1c5-de12999f89aa"
   },
   "outputs": [],
   "source": [
    "# Initialize Pytorch's CocoDetection dataset, apply transforms.\n",
    "dataset_test = datasets.CocoDetection('./val2017','./annotations/instances_val2017.json', transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Initialize dataloader with the dataset\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "id": "vR1KQdlc0hpR",
    "outputId": "3356e581-8e00-4cd0-a691-8a6ac7b0a56f"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Faster-RCNN is a deep-learning based object detection method.\n",
    "It is available pre-trained from PyTorch\n",
    "\"\"\"\n",
    "\n",
    "# Initialize Faster-RCNN model\n",
    "fasterRCNN = pretrained_models.detection.fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be3wSzKg0huX"
   },
   "outputs": [],
   "source": [
    "def detect_objects_in_image(model,image):\n",
    "\t\t\"\"\"\n",
    "\t\tObject detection using trained Faster-RCNN.\n",
    "\n",
    "\t\tArguments:\n",
    "\t\tmodel : Trained Faster-RCNN model\n",
    "\t\timage : A pytorch tensor of shape [B,3,H,W] with pixels normalized to 0-1 range\n",
    "\t\t\"\"\"\n",
    "\t\t\n",
    "\t\t# Put the model in eval mode.\n",
    "\t\tmodel = model.eval()\n",
    "\n",
    "\t\t# Get the object detections on the image\n",
    "\t\tdetections = model(image)[0]\n",
    "\n",
    "\n",
    "\t\tCOLORS = np.random.uniform(0, 1, size=(max_id, 3))\n",
    "\n",
    "\t\torig = image.squeeze().cpu().numpy().transpose(1,2,0).copy()\n",
    "\n",
    "\t\t# loop over the detections\n",
    "\t\tfor i in range(0, len(detections[\"boxes\"])):\n",
    "\t\t\t# extract the confidence (i.e., probability) associated with the\n",
    "\t\t\t# prediction\n",
    "\t\t\tconfidence = detections[\"scores\"][i]\n",
    "\t\t\tif confidence > 0.9:\n",
    "\t\t\t\t# filter out weak detections by ensuring the confidence is\n",
    "\t\t\t\t# greater than the minimum confidence\n",
    "\t\t\t\t# extract the index of the class label from the detections,\n",
    "\t\t\t\t# then compute the (x, y)-coordinates of the bounding box\n",
    "\t\t\t\t# for the object\n",
    "\t\t\t\tidx = int(detections[\"labels\"][i])\n",
    "\t\t\t\tbox = detections[\"boxes\"][i].detach().cpu().numpy()\n",
    "\t\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\t\t\t\t# display the prediction to our terminal\n",
    "\t\t\t\tlabel = \"{}: {:.2f}%\".format(classid_to_name[idx], confidence * 100)\n",
    "\t\t\t\tprint(\"[INFO] {}\".format(label))\n",
    "\t\t\t\t# draw the bounding box and label on the image\n",
    "\t\t\t\tcv2.rectangle(orig, (startX, startY), (endX, endY),\n",
    "\t\t\t\t\tCOLORS[idx], 2)\n",
    "\t\t\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n",
    "\t\t\t\tcv2.putText(orig, label, (startX, y),\n",
    "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n",
    "\t\t\t\n",
    "\t\t# show the output image\n",
    "\t\tplt.figure(figsize=(10,10))\n",
    "\t\tplt.imshow(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 664
    },
    "id": "KeAqSplI0hrz",
    "outputId": "4df15739-b8b1-45d7-c8d8-7a15b362e65f"
   },
   "outputs": [],
   "source": [
    "# Get one Test image from the data loader. You can do multiple next operations, to get a different image.\n",
    "image, labels = next(iter(data_loader_test))\n",
    "\n",
    "# Move the image and the model to GPU\n",
    "image = image.cuda()\n",
    "model = fasterRCNN.cuda()\n",
    "\n",
    "detect_objects_in_image(model,image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "5X41EYxDPszo",
    "outputId": "5f492987-e4d7-476d-e5bf-538f2e1719e3"
   },
   "outputs": [],
   "source": [
    "# With a random image from the internet\n",
    "!wget https://media-cdn.tripadvisor.com/media/photo-s/01/c0/38/f7/gower-street-one-way.jpg -O 'gower_street.jpg'\n",
    "img = cv2.imread('gower_street.jpg')\n",
    "img = img[:,:,[2,1,0]]\n",
    "img = (img - np.min(img))/(np.max(img)-np.min(img))\n",
    "image = torch.unsqueeze(torch.from_numpy(img),0).permute(0,3,1,2).float().cuda()\n",
    "\n",
    "detect_objects_in_image(model,image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIZ2OZnLgc3F"
   },
   "source": [
    "# Example 3\n",
    "Visualize NN activations pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "fcffc35d31934b9e820b656ab6d52789",
      "d2defa0e863e40c393013c9dba66dd75",
      "a271019f5bb84ddc843f54ca6a09bb83",
      "64b0d084e2814192aabec98d0738e1ea",
      "d59e59075f1a43b980b6a4cfc4049079",
      "ef4186e5b1204aa89ab18bc2002a5213",
      "537f6d55da554ca386d974fc51ff735f",
      "48fc0b7214994f669c5788fc8d89c492",
      "025e7107238f4fb0b270740f8c15053b",
      "e7d6edba060e452182c54f6e5f157dfe",
      "6b8ac183ef504fb486d6af4319e90556"
     ]
    },
    "id": "Lc0ZvDWdsIlk",
    "outputId": "432b3174-2cba-454c-8e46-d6801ab0d710"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We'll now visualize VGG's layer activations on an image.\n",
    "\"\"\"\n",
    "\n",
    "# Load pretrained VGG-16\n",
    "vgg16 = pretrained_models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTGSdQKjgeTY"
   },
   "outputs": [],
   "source": [
    "def plot_image(img):\n",
    "    \"\"\"\n",
    "    A utitlity function to normalize and display an image\n",
    "    \"\"\"\n",
    "    \n",
    "    img = img.detach().squeeze().permute(1,2,0)\n",
    "\n",
    "    # mean and std list for channels (Imagenet)\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).float().reshape(1,1,3)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).float().reshape(1,1,3)\n",
    "\n",
    "    img *= std\n",
    "    img += mean\n",
    "    img = torch.clamp(img, 0.0, 1.0)\n",
    "    \n",
    "    np_image = img.cpu().numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(np_image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTDwOp63geQr"
   },
   "outputs": [],
   "source": [
    "def visualize_cnn_filters(model, cnn_layer, selected_filter):\n",
    "    \"\"\"\n",
    "    Visualize a single filter of a given layer of the network\n",
    "\n",
    "    Arguments:\n",
    "    model : The neural network model\n",
    "    cnn_layer : Layer number inside this network\n",
    "    selected_filter : Filter number in the layer\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "\n",
    "    # Generate a random image\n",
    "    random_image = torch.rand([1,3,224,224])\n",
    "    random_image = Variable(random_image, requires_grad=True)\n",
    "\n",
    "    # Define optimizer for the image\n",
    "    optimizer = Adam([random_image], lr=0.1, weight_decay=1e-6)\n",
    "\n",
    "    for i in range(1, 100):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Assign create image to a variable to move forward in the model\n",
    "        x = random_image.cuda()\n",
    "    \n",
    "        for index, layer in enumerate(model):\n",
    "            # Forward pass layer by layer\n",
    "            # x is not used after this point because it is only needed to trigger\n",
    "            # the forward hook function\n",
    "            x = layer(x)\n",
    "            # Only need to forward until the selected layer is reached\n",
    "            if index == cnn_layer:\n",
    "                # (forward hook function triggered)\n",
    "                break\n",
    "\n",
    "        filter_output = x[0, selected_filter]\n",
    "\n",
    "        # Loss function is the mean of the output of the selected layer/filter\n",
    "        # We try to minimize the mean of the output of that specific filter\n",
    "        loss = -torch.mean(filter_output)\n",
    "        \n",
    "        # Backward - propagate the loss through the layers up to the input image\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the input image based on computed gradients\n",
    "        optimizer.step()\n",
    "    \n",
    "\n",
    "    plot_image(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Ro5wtqpRgeWf",
    "outputId": "27fa4167-5ae0-4be7-cd45-77dee9a64de9"
   },
   "outputs": [],
   "source": [
    "cnn_layer = 17\n",
    "filter_pos = 5\n",
    "visualize_cnn_filters(vgg16.features, cnn_layer, filter_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2KmN2MYvUUb"
   },
   "source": [
    "What are patterns are recognized by other filter ? Try to change the 'cnn_layer' and 'filter_pos' variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ew6Pnq7fDEjV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3W_p7QqbgegS"
   },
   "source": [
    "# Example 4\n",
    "Visualize which piece of image activates neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D7i3_yLMmJPi",
    "outputId": "c6ad4aeb-c1e6-4629-bda9-6ad28b174551"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get some image from the internet, load it locally\n",
    "\"\"\"\n",
    "\n",
    "!wget https://raw.githubusercontent.com/utkuozbulak/pytorch-cnn-visualizations/master/input_images/spider.png 'spider.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "Yc3Vwmm0yKug",
    "outputId": "3076b5e8-c098-4748-cfcf-de540258b708"
   },
   "outputs": [],
   "source": [
    "# Load the image as a pytorch tensor\n",
    "image = load_custom_image('spider.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCrk9cQoyGzO"
   },
   "outputs": [],
   "source": [
    "def visualize_cnn_filters(model, input_image, cnn_layer):\n",
    "    \"\"\"\n",
    "    Find out which parts of the image activate a particular filter in a given layer of the network\n",
    "\n",
    "    Arguments:\n",
    "    model : The neural network model\n",
    "    input_image : The input image to test on\n",
    "    cnn_layer : A layer number into the network\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model = model.cuda()\n",
    "    input_image = input_image.cuda()\n",
    "\n",
    "    model.zero_grad()\n",
    "    # Forward pass\n",
    "    x = input_image\n",
    "    for index, layer in enumerate(model.features):\n",
    "        # Forward pass layer by layer\n",
    "        # x is not used after this point because it is only needed to trigger\n",
    "        # the forward hook function\n",
    "        x = layer(x)\n",
    "        # Only need to forward until the selected layer is reached\n",
    "        if index == cnn_layer:\n",
    "            # (forward hook function triggered)\n",
    "            break\n",
    "\n",
    "\n",
    "    scale = input_image.size(-1)/x.size(-1)\n",
    "\n",
    "    # We upsample the filter activation to the image size, so we can overlay the activation\n",
    "    # on top of the image, to see which part of the image contributed to the activation\n",
    "    return torch.nn.functional.upsample(x, scale_factor=scale, mode='bilinear')[0, filter_pos].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P0zX6_V6P5f"
   },
   "outputs": [],
   "source": [
    "vgg16 = pretrained_models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "SMLbEv13LDJ1",
    "outputId": "f7b301f6-27ab-448b-caba-8e2e31403d0c"
   },
   "outputs": [],
   "source": [
    "# Display original image\n",
    "from IPython.display import Image\n",
    "Image('spider.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "G6SuBJ0mgfb4",
    "outputId": "23311618-9abc-4cfc-f1ba-7506ca54b192"
   },
   "outputs": [],
   "source": [
    "# Play around with cnn_layer and filter_pos\n",
    "cnn_layer = 5\n",
    "\n",
    "activations = visualize_cnn_filters(vgg16, image.cuda(), cnn_layer)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(activations)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TA_mptivation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "025e7107238f4fb0b270740f8c15053b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "07fdd2088bda401382643496e800ff7d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1e5a6e4a979b4a668b95fd422eb575f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ee80943b8a549de99b41534cea0e34a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f2435c919df47e4813cae97d5bfe9b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41e67cf900f148448f7f2d31d8ddafed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45a6ada590e045bb8cf92bd276725716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48fc0b7214994f669c5788fc8d89c492": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "537f6d55da554ca386d974fc51ff735f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "553ae8541d474af29a68334d723180af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "58758fb0a34c4a2a8c8a55c5df15f7f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "593ce3e905c244e280eef58f071c6312": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6188895479914d6c879ad151acc23b56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41e67cf900f148448f7f2d31d8ddafed",
      "placeholder": "​",
      "style": "IPY_MODEL_07fdd2088bda401382643496e800ff7d",
      "value": ""
     }
    },
    "6434d040e1ec4290bcc17cc83f7f186f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6188895479914d6c879ad151acc23b56",
       "IPY_MODEL_eae088d584f44016ac781564de939e87",
       "IPY_MODEL_974818abc603428c84f745fdf6c8e3fa"
      ],
      "layout": "IPY_MODEL_593ce3e905c244e280eef58f071c6312"
     }
    },
    "64b0d084e2814192aabec98d0738e1ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_025e7107238f4fb0b270740f8c15053b",
      "max": 553433881,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_48fc0b7214994f669c5788fc8d89c492",
      "value": 553433881
     }
    },
    "67b546d1833f4d1bbd74e41839cfc437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ee80943b8a549de99b41534cea0e34a",
      "placeholder": "​",
      "style": "IPY_MODEL_3f2435c919df47e4813cae97d5bfe9b3",
      "value": " 170499072/? [00:03&lt;00:00, 54062691.74it/s]"
     }
    },
    "6b8ac183ef504fb486d6af4319e90556": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f5a317063d64eeda925c7bf2b2e3e7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79caf1d9277a4f61be502d131f5900f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd60d5286eae470b84168ba5643fa459",
       "IPY_MODEL_e1b74aa2c2b24d0a94cad31a3b3393b1",
       "IPY_MODEL_67b546d1833f4d1bbd74e41839cfc437"
      ],
      "layout": "IPY_MODEL_1e5a6e4a979b4a668b95fd422eb575f1"
     }
    },
    "974818abc603428c84f745fdf6c8e3fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de53205fdccc41108b6da2eb9e4b30a8",
      "placeholder": "​",
      "style": "IPY_MODEL_6f5a317063d64eeda925c7bf2b2e3e7f",
      "value": " 9913344/? [00:00&lt;00:00, 49320141.04it/s]"
     }
    },
    "a271019f5bb84ddc843f54ca6a09bb83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_537f6d55da554ca386d974fc51ff735f",
      "placeholder": "​",
      "style": "IPY_MODEL_ef4186e5b1204aa89ab18bc2002a5213",
      "value": "100%"
     }
    },
    "d2defa0e863e40c393013c9dba66dd75": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d59e59075f1a43b980b6a4cfc4049079": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6b8ac183ef504fb486d6af4319e90556",
      "placeholder": "​",
      "style": "IPY_MODEL_e7d6edba060e452182c54f6e5f157dfe",
      "value": " 528M/528M [00:07&lt;00:00, 45.9MB/s]"
     }
    },
    "d72765fb9bb3448cb51876401603bb9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d81f37d4b1494eb4ba9442a0c83764e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d91e902730b64b2e83effd4ba193d418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd60d5286eae470b84168ba5643fa459": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_58758fb0a34c4a2a8c8a55c5df15f7f4",
      "placeholder": "​",
      "style": "IPY_MODEL_553ae8541d474af29a68334d723180af",
      "value": ""
     }
    },
    "de53205fdccc41108b6da2eb9e4b30a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1b74aa2c2b24d0a94cad31a3b3393b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d72765fb9bb3448cb51876401603bb9f",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d91e902730b64b2e83effd4ba193d418",
      "value": 170498071
     }
    },
    "e7d6edba060e452182c54f6e5f157dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eae088d584f44016ac781564de939e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45a6ada590e045bb8cf92bd276725716",
      "max": 9912422,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d81f37d4b1494eb4ba9442a0c83764e1",
      "value": 9912422
     }
    },
    "ef4186e5b1204aa89ab18bc2002a5213": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcffc35d31934b9e820b656ab6d52789": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a271019f5bb84ddc843f54ca6a09bb83",
       "IPY_MODEL_64b0d084e2814192aabec98d0738e1ea",
       "IPY_MODEL_d59e59075f1a43b980b6a4cfc4049079"
      ],
      "layout": "IPY_MODEL_d2defa0e863e40c393013c9dba66dd75"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
